{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "56tfDxbWVq9b"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Scraping a Site**\n",
        "### Extract links for all countries from the website https://starbucksmenuprices.com/.\n"
      ],
      "metadata": {
        "id": "56tfDxbWVq9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Install Necessary Libraries**\n",
        "Python libraries extend the functionality of Python. Here, we need:\n",
        "*   requests: To fetch the webpage.\n",
        "*   BeautifulSoup (from bs4): To parse and extract data from the HTML.\n",
        "### **Command:**"
      ],
      "metadata": {
        "id": "UTkEIC3CWIvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install requests beautifulsoup4"
      ],
      "metadata": {
        "id": "wf-x5vXBWJLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Import Libraries**\n",
        "We start the Python script by importing the libraries we installed. Think of this as unlocking tools we’ll need for our task.\n",
        "*   **import requests**: Enables us to send a request to a webpage.\n",
        "*   **from bs4 import BeautifulSoup**: Allows us to use BeautifulSoup for extracting data.\n",
        "### **Command:**"
      ],
      "metadata": {
        "id": "OrNyesRYWegF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import requests  # For fetching the webpage\n",
        "from bs4 import BeautifulSoup  # For parsing the webpage"
      ],
      "metadata": {
        "id": "WR3ARXxfWZY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Fetch the Webpage Content**\n",
        "Webpages are made of HTML (a markup language for displaying content). To analyze it, we first need to download the HTML using Python.\n",
        "*  **url = '...'**: This variable stores the URL of the website we want to scrape.\n",
        "*  **requests.get(url)**: Sends a request to the server to get the webpage's content.\n",
        "*   **response.status_code**: Checks the server's response. A code of 200 means the request was successful."
      ],
      "metadata": {
        "id": "tJU96afEWt9W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# URL of the webpage to scrape\n",
        "url = 'https://starbucksmenuprices.com/'\n",
        "\n",
        "# Send a request to the server\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully fetched the webpage!\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8UNA0YZXAxP",
        "outputId": "4b0c701e-a0bc-4835-8b72-9e3478a20b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully fetched the webpage!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Common Status Codes:**\n",
        "*   200 OK: The request was successful.\n",
        "*   201 Created: The request has been fulfilled, resulting in the creation of a new resource.\n",
        "*   204 No Content: The server successfully processed the request, but is not returning any content.\n",
        "*   301 Moved Permanently: The requested resource has been permanently moved to a new location.\n",
        "*   302 Found (Temporary Redirect): The requested resource has been temporarily moved to a new location.\n",
        "*   400 Bad Request: The server cannot or will not process the request due to an apparent client error.\n",
        "*   401 Unauthorized: The request requires user authentication.\n",
        "*   403 Forbidden: The server understood the request, but refuses to fulfill it.\n",
        "*   404 Not Found: The server cannot find the requested resource.\n",
        "*   500 Internal Server Error: The server encountered an unexpected condition that prevented it from fulfilling the request.\n",
        "*   503 Service Unavailable: The server is currently unable to handle the request due to a temporary overload or maintenance."
      ],
      "metadata": {
        "id": "awzb8luHdFja"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Parse the HTML Content**\n",
        "Now that we have the HTML, we need to make it readable for Python using BeautifulSoup.\n",
        "*  **response.text**: The raw HTML text of the webpage.\n",
        "*   **BeautifulSoup(..., 'html.parser')**: Converts the raw HTML into a structured format that Python can easily work with.\n",
        "*   **soup.prettify()**: Prints the HTML in an indented format, making it easier to inspect.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Heh1vR1FXUqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse the webpage content with BeautifulSoup\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Print the HTML content to understand its structure\n",
        "# print(soup.prettify())\n"
      ],
      "metadata": {
        "id": "-U2hL-IFX0Jg"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Locate the Links**\n",
        "To extract links, inspect the website’s structure using your browser’s developer tools (right-click > \"Inspect\").\n",
        "\n",
        "*   Identify the < a > tags (used for links) within the < ul > list elements.\n",
        "*  **soup.find_all('ul')**: Finds all < ul > (unordered list) elements on the page.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9IdlMyIyX4WT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find all <ul> elements containing the country links\n",
        "sections = soup.find_all('ul')  # Locate all <ul> elements\n",
        "\n",
        "# Lists in Python: The result is a list, which can store multiple items.\n",
        "print(sections[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPb3iMD1X0tD",
        "outputId": "5e92e3b6-b018-4ecf-a034-87f0e2d48bdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<ul class=\"sub-menu\">\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-32\" id=\"menu-item-32\"><a href=\"https://starbucksmenuprices.com/starbucks-au-prices/\">Australia</a></li>\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-42\" id=\"menu-item-42\"><a href=\"https://starbucksmenuprices.com/starbucks-brasil-precos/\">Brasil</a></li>\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-70\" id=\"menu-item-70\"><a href=\"https://starbucksmenuprices.com/starbucks-%d1%86%d0%b5%d0%bd%d0%b8/\">Bulgaria</a></li>\n",
            "<li class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-58\" id=\"menu-item-58\"><a href=\"https://starbucksmenuprices.com/starbucks-canada-menu/\">Canada</a></li>\n",
            "</ul>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of List:\n",
        "my_list = ['apple', 'banana', 'cherry']\n",
        "print(my_list[0],my_list[1],my_list[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7_XXuejYaDE",
        "outputId": "6886139a-bd5d-4045-d4ac-6415987fdd6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple banana cherry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Extract Links**\n",
        "Now, loop through each < ul > section to find < a > tags (anchors), which represent links.\n",
        "\n",
        "*   **link.text.strip()**: Extracts the text (e.g., \"Australia\") and removes extra spaces.\n",
        "*  **link.get('href')**: Retrieves the URL linked to the < a > tag.\n",
        "*  **country_links.append({...})**: Adds a dictionary with country name and URL to the list.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e6kLrbMGZgXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract links from the <ul> sections\n",
        "country_links = []  # Empty list to store results\n",
        "\n",
        "for section in sections:\n",
        "    links = section.find_all('a')  # Find all <a> tags in each section\n",
        "    for link in links:\n",
        "        country_name = link.text.strip()  # Get the visible text of the link\n",
        "        country_url = link.get('href')  # Get the href attribute (URL)\n",
        "        country_links.append({'Country': country_name, 'URL': country_url})\n"
      ],
      "metadata": {
        "id": "O6lTXhJVY5jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of Loop:\n",
        "for fruit in ['apple', 'banana', 'cherry']:\n",
        "    print(fruit)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7Y1LNOMZ4Cz",
        "outputId": "cfde1e36-cc55-4414-b074-9acfb2c84580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "apple\n",
            "banana\n",
            "cherry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: Store Results in a DataFrame**\n",
        "DataFrames are tables provided by the **pandas** library, making it easy to organize and analyze data.\n",
        "*   **pd.DataFrame()**: Converts a list of dictionaries into a tabular format.\n",
        "*   **df.head()**: Displays the first 5 rows.\n",
        "\n"
      ],
      "metadata": {
        "id": "TZwR1BEIaEMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for working with data\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the list of dictionaries into a DataFrame\n",
        "df = pd.DataFrame(country_links)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sagggYqvaAjJ",
        "outputId": "539a2170-5552-463f-effd-e0d00c300f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Country                                                URL\n",
            "0        A-C                                                  #\n",
            "1  Australia  https://starbucksmenuprices.com/starbucks-au-p...\n",
            "2     Brasil  https://starbucksmenuprices.com/starbucks-bras...\n",
            "3   Bulgaria  https://starbucksmenuprices.com/starbucks-%d1%...\n",
            "4     Canada  https://starbucksmenuprices.com/starbucks-cana...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 8: Save Results to a CSV File**\n",
        "Finally, save the data to a CSV file, which can be opened in Excel or analyzed further.\n",
        "*   **to_csv()**: Exports the DataFrame to a file.\n",
        "*   **index=False**: Prevents saving row numbers in the CSV.\n",
        "\n"
      ],
      "metadata": {
        "id": "kZ9B3yLXaYzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('starbucks_country_links.csv', index=False)\n",
        "print(\"Saved country links to starbucks_country_links.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMcQbPTHaRzf",
        "outputId": "b78cbd9d-97cc-4e0b-b15d-eda4e60692e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved country links to starbucks_country_links.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Complete Script**"
      ],
      "metadata": {
        "id": "SWH-gjY-anPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Fetch the webpage content\n",
        "url = 'https://starbucksmenuprices.com/'\n",
        "response = requests.get(url)\n",
        "if response.status_code == 200:\n",
        "    print(\"Successfully fetched the webpage!\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
        "\n",
        "# Step 2: Parse the HTML content\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Step 3: Find all <ul> elements\n",
        "sections = soup.find_all('ul')\n",
        "\n",
        "# Step 4: Extract links\n",
        "country_links = []\n",
        "for section in sections:\n",
        "    links = section.find_all('a')\n",
        "    for link in links:\n",
        "        country_name = link.text.strip()\n",
        "        country_url = link.get('href')\n",
        "        country_links.append({'Country': country_name, 'URL': country_url})\n",
        "\n",
        "# Step 5: Convert to DataFrame\n",
        "df = pd.DataFrame(country_links)\n",
        "print(df.head())  # Display the first 5 rows\n",
        "\n",
        "# Step 6: Save to CSV\n",
        "df.to_csv('starbucks_country_links.csv', index=False)\n",
        "print(\"Saved country links to starbucks_country_links.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTBOre91akMU",
        "outputId": "8df09c4e-0447-4e85-b027-d8f62e2dc631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully fetched the webpage!\n",
            "     Country                                                URL\n",
            "0        A-C                                                  #\n",
            "1  Australia  https://starbucksmenuprices.com/starbucks-au-p...\n",
            "2     Brasil  https://starbucksmenuprices.com/starbucks-bras...\n",
            "3   Bulgaria  https://starbucksmenuprices.com/starbucks-%d1%...\n",
            "4     Canada  https://starbucksmenuprices.com/starbucks-cana...\n",
            "Saved country links to starbucks_country_links.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Extracting Starbucks Prices Data**\n",
        "### Example of scraping hot coffee price data."
      ],
      "metadata": {
        "id": "-LMQgctXbC45"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 1: Load the Links**\n",
        "*   **pd.read_csv()**: Reads the CSV file containing country links into a DataFrame.\n",
        "*   **links_file**: The file path of the CSV file.\n",
        "\n"
      ],
      "metadata": {
        "id": "NeWIMqaAbuPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "links_file = 'starbucks_country_links.csv'  # File containing country links\n",
        "country_links = pd.read_csv(links_file)  # Read the CSV file into a DataFrame"
      ],
      "metadata": {
        "id": "34R8JoI8bJuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 2: Filter Valid Links**\n",
        "*   **Filter Rows**: ~country_links['URL'].str.contains('#', na=False) excludes rows where the URL contains #.\n",
        "*   **iloc[0]**: Selects the first valid row.\n",
        "*   **Format Country Name**: Converts the country name to lowercase and replaces spaces with hyphens for file naming."
      ],
      "metadata": {
        "id": "7LVG-1Xub9Iw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_links = country_links[~country_links['URL'].str.contains('#', na=False)]  # Filter rows without '#'\n",
        "if valid_links.empty:\n",
        "    print(\"No valid links found in the file.\")\n",
        "    exit()\n",
        "\n",
        "first_link = valid_links.iloc[0]  # Select the first valid row\n",
        "country_url = first_link['URL']  # Extract the URL from the first valid row\n",
        "country_name = first_link['Country'].lower().replace(' ', '-')  # Extract and format the country name\n"
      ],
      "metadata": {
        "id": "UC_gy_nkb8JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 3: Fetch the Webpage**\n",
        "*   **requests.get(url)**: Fetches the HTML content of the URL.\n",
        "*   **Check Status Code**: Ensures the webpage was successfully fetched (200 status code).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xtc5vnQ_cknT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(country_url)\n",
        "if response.status_code == 200:\n",
        "    print(f\"Successfully fetched the page: {country_url}\")\n",
        "else:\n",
        "    print(f\"Failed to fetch webpage. Status code: {response.status_code}\")\n",
        "    exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwYfH5dAb3Cv",
        "outputId": "dbb1dcf2-dbdd-4e91-fbba-4bb691d87347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully fetched the page: https://starbucksmenuprices.com/starbucks-au-prices/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 4: Parse the HTML**\n",
        "*   **BeautifulSoup(..., 'html.parser')**: Parses the HTML content into a structured format."
      ],
      "metadata": {
        "id": "k0DrR1tjdnZo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "b7NWyL2McptM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 5: Locate \"h2\" Section**\n",
        "*   **Find < h2 > Heading**: Searches for the \"h2\" heading.\n",
        "*   **Find Parent Table**: If the heading is found, locate the parent table containing the data."
      ],
      "metadata": {
        "id": "AeGYq65neXz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hot_coffee_heading = soup.find('h2')  # Locate the \"h2\" section heading\n",
        "if hot_coffee_heading:\n",
        "    hot_coffee_table = hot_coffee_heading.find_parent('table')  # Find the parent table containing the data\n",
        "else:\n",
        "    print(\"'Hot Coffee' section not found on the page.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "2w5i8SDpeTqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 6: Extract Data**\n",
        "*   **Find Rows**: Selects rows with class item.\n",
        "*  **Extract Columns**: Extracts text from each column and cleans it."
      ],
      "metadata": {
        "id": "LS9viHetekWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hot_coffee_data = []  # List to store extracted data\n",
        "if hot_coffee_table:\n",
        "    rows = hot_coffee_table.find_all('tr', class_='item')  # Find all rows with class \"item\"\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')  # Find all columns in the row\n",
        "        cols = [col.string.strip() for col in cols]  # Clean the text\n",
        "        if cols:  # Skip empty rows\n",
        "            hot_coffee_data.append(cols)"
      ],
      "metadata": {
        "id": "I75UQkcxegiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Step 7: Save Data**\n",
        "*   **Dynamic File Name**: Includes the country name in the file name.\n",
        "*  **Save to CSV**: Exports the data to a CSV file."
      ],
      "metadata": {
        "id": "44TUK1Lsg2TA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if hot_coffee_data:\n",
        "    df_hot_coffee = pd.DataFrame(hot_coffee_data, columns=['Item', 'Price'])  # Create a DataFrame\n",
        "    output_file = f'hot_coffee_prices_{country_name}.csv'  # Generate file name with country name\n",
        "    df_hot_coffee.to_csv(output_file, index=False)  # Save to CSV\n",
        "    print(f\"Saved 'Hot Coffee' prices to {output_file}\")\n",
        "    print(df_hot_coffee)  # Print the result\n",
        "else:\n",
        "    print(\"No 'Hot Coffee' data found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RZD09uUetEr",
        "outputId": "4ef5f214-595c-4b12-f1a2-8be47482c132"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 'Hot Coffee' prices to hot_coffee_prices_australia.csv\n",
            "                              Item  Price\n",
            "0                     Banana Bread  $6.30\n",
            "1                 Butter Croissant  $5.78\n",
            "2                 Almond Croissant  $5.78\n",
            "3                Pain Au Chocolate  $5.50\n",
            "4                 Pain Au Chocolat  $6.00\n",
            "..                             ...    ...\n",
            "74               Caramel Macchiato  $6.88\n",
            "75           White Chocolate Mocha  $6.16\n",
            "76                     Caffé Mocha  $6.35\n",
            "77         Caramel Cloud Macchiato  $8.00\n",
            "78  Honeycomb Salted Caramel Latte  $7.30\n",
            "\n",
            "[79 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QU5qaet1g9kG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}